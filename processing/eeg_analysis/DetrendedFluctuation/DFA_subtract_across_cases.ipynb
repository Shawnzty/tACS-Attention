{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# the following import is required for matplotlib < 3.2:\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, ttest_rel\n",
    "from scipy.signal import butter, filtfilt\n",
    "import mne\n",
    "import eeg_analysis.funcs4eeg as fe\n",
    "import re\n",
    "import imp\n",
    "import ast\n",
    "import behavior.func4behav as fb\n",
    "imp.reload(fe)\n",
    "imp.reload(fb)\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import resample\n",
    "from scipy.ndimage import zoom\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def align_slow(eeg, case, fs):\n",
    "    if 'endo' in case:\n",
    "        jump_from, jump_to = int((1.5+1+0.5)*fs), int((1.5+1+1)*fs)\n",
    "    elif 'exo' in case:\n",
    "        jump_from, jump_to = int((1.5+0.033*4+0.5)*fs), int((1.5+0.033*4+1)*fs)\n",
    "    \n",
    "    for channel in range(len(eeg)):\n",
    "        eeg[channel] = np.concatenate((eeg[channel][:,:jump_from], eeg[channel][:,jump_to:]), axis=1)\n",
    "        \n",
    "    return eeg\n",
    "\n",
    "case_title = 'endo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def dfa_alpha(data, min_win=25, max_win=200):\n",
    "    dfa_data = fu.toAggregated(data)\n",
    "    pydfa = fathon.DFA(dfa_data)\n",
    "    wins = fu.linRangeByStep(min_win, max_win)\n",
    "    n,F = pydfa.computeFlucVec(wins, revSeg=True, polOrd=3)\n",
    "    H, H_intercept = pydfa.fitFlucVec()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'exo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra\n",
    "\n",
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'all'\n",
    "case = 'all'\n",
    "\n",
    "fs = 1200\n",
    "\n",
    "watch = '1 fixation'\n",
    "tmin = 0 # include fix or not?\n",
    "tmax = 1.5\n",
    "\n",
    "highpass = None\n",
    "lowpass = None\n",
    "\n",
    "sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "\n",
    "\n",
    "stage = [0, 1.5]\n",
    "sessions = [sb, sa, rb, ra]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        tmp = np.empty(())\n",
    "        data = sessions[i][channel]\n",
    "        t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "        for trial_n in range(data.shape[0]):\n",
    "            one_trial = data[trial_n, t_start:t_end]\n",
    "            alpha = dfa_alpha(one_trial)\n",
    "            tmp = np.append(tmp, alpha)\n",
    "        # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "        mask = (tmp>0) & (tmp<2)\n",
    "        filtered_tmp = tmp[mask]\n",
    "        dfa_table_num[i, channel] = filtered_tmp.shape[0]\n",
    "        dfa_table_se[i, channel] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_fixation', dfa_table_se)\n",
    "np.save('dfa_num_fixation', dfa_table_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('dfa_table_'+case_title, dfa_table)\n",
    "# dfa_table = np.load('dfa_table_'+case_title+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# band = 0\n",
    "# fast, slow = bp_table[0,0,:,band], bp_table[0,1,:,band]\n",
    "\n",
    "# plt.scatter(range(len(fast)), fast, color='blue', label='fast')\n",
    "# plt.scatter(range(len(slow)), slow, color='red', label='slow')\n",
    "# plt.title(band)\n",
    "# plt.legend()\n",
    "# plt.ylim([0, 7e-8])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1402255256283456 1.4041407412572193\n"
     ]
    }
   ],
   "source": [
    "endo_means, exo_means, fix_means = np.load('dfa_data/dfa_mean_endo.npy'), np.load('dfa_data/dfa_mean_exo.npy'), np.load('dfa_data/dfa_mean_fixation.npy')\n",
    "exo_means = exo_means[:, :, 0]\n",
    "endo_nums, exo_nums, fix_nums = np.load('dfa_data/dfa_num_endo.npy'), np.load('dfa_data/dfa_num_exo.npy'), np.load('dfa_data/dfa_num_fixation.npy')\n",
    "exo_nums = exo_nums[:, :, 0]\n",
    "endo_se, exo_se, fix_se = np.load('dfa_data/dfa_se_endo.npy'), np.load('dfa_data/dfa_se_exo.npy'), np.load('dfa_data/dfa_se_fixation.npy')\n",
    "exo_se = exo_se[:, :, 0]\n",
    "\n",
    "print(np.min(fix_means), np.max(fix_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFA subtracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wait for cue for endo\n",
    "endo_dfa_subtracts, exo_dfa_subtracts, fix_dfa_subtracts = np.zeros((2, 32)),  np.zeros((2, 32)),  np.zeros((2, 32))\n",
    "endo_dfa_subtracts[0,:], endo_dfa_subtracts[1,:] = endo_means[1,:,1] - endo_means[0,:,1], endo_means[3,:,1] - endo_means[2,:,1]\n",
    "exo_dfa_subtracts[0,:], exo_dfa_subtracts[1,:] = exo_means[1,:] - exo_means[0,:], exo_means[3,:] - exo_means[2,:]\n",
    "fix_dfa_subtracts[0,:], fix_dfa_subtracts[1,:] = fix_means[1,:] - fix_means[0,:], fix_means[3,:] - fix_means[2,:]\n",
    "\n",
    "endo_se_subtracts, exo_se_subtracts, fix_se_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_se_subtracts[0,:], endo_se_subtracts[1,:] = np.sqrt(endo_se[1,:,1]**2 + endo_se[0,:,1]**2), np.sqrt(endo_se[3,:,1]**2 + endo_se[2,:,1]**2)\n",
    "exo_se_subtracts[0,:], exo_se_subtracts[1,:] = np.sqrt(exo_se[1,:]**2 + exo_se[0,:]**2), np.sqrt(exo_se[3,:]**2 + exo_se[2,:]**2)\n",
    "fix_se_subtracts[0,:], fix_se_subtracts[1,:] = np.sqrt(fix_se[1,:]**2 + fix_se[0,:]**2), np.sqrt(fix_se[3,:]**2 + fix_se[2,:]**2)\n",
    "\n",
    "endo_num_subtracts, exo_num_subtracts, fix_num_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_num_subtracts[0,:], endo_num_subtracts[1,:] = endo_nums[1,:,1] + endo_nums[0,:,1], endo_nums[3,:,1] + endo_nums[2,:,1]\n",
    "exo_num_subtracts[0,:], exo_num_subtracts[1,:] = exo_nums[1,:] + exo_nums[0,:], exo_nums[3,:] + exo_nums[2,:]\n",
    "fix_num_subtracts[0,:], fix_num_subtracts[1,:] = fix_nums[1,:] + fix_nums[0,:], fix_nums[3,:] + fix_nums[2,:]\n",
    "\n",
    "dfa_subtracts, se_subtracts, num_subtracts = np.zeros((2, 32, 3)), np.zeros((2, 32, 3)), np.zeros((2, 32, 3))\n",
    "dfa_subtracts[:,:,0], dfa_subtracts[:,:,1], dfa_subtracts[:,:,2] = fix_dfa_subtracts, endo_dfa_subtracts, exo_dfa_subtracts\n",
    "se_subtracts[:,:,0], se_subtracts[:,:,1], se_subtracts[:,:,2] = fix_se_subtracts, endo_se_subtracts, exo_se_subtracts\n",
    "num_subtracts[:,:,0], num_subtracts[:,:,1], num_subtracts[:,:,2] = fix_num_subtracts, endo_num_subtracts, exo_num_subtracts\n",
    "\n",
    "# common increase / decrease\n",
    "dfa_subtracts_positive = np.where(dfa_subtracts>0, 1, 0)\n",
    "dfa_subtracts_negative = np.where(dfa_subtracts<0, 1, 0)\n",
    "sham_positive = dfa_subtracts_positive[0,:,0] * dfa_subtracts_positive[0,:,1] * dfa_subtracts_positive[0,:,2]\n",
    "sham_negative = dfa_subtracts_negative[0,:,0] * dfa_subtracts_negative[0,:,1] * dfa_subtracts_negative[0,:,2]\n",
    "real_positive = dfa_subtracts_positive[1,:,0] * dfa_subtracts_positive[1,:,1] * dfa_subtracts_positive[1,:,2]\n",
    "real_negative = dfa_subtracts_negative[1,:,0] * dfa_subtracts_negative[1,:,1] * dfa_subtracts_negative[1,:,2]\n",
    "sham_increase_channels = np.where(sham_positive==1)[0]\n",
    "sham_decrease_channels = np.where(sham_negative==1)[0]\n",
    "real_increase_channels = np.where(real_positive==1)[0]\n",
    "real_decrease_channels = np.where(real_negative==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_grand_mean_and_se(means, ses, sample_sizes):\n",
    "     # Number of cases is the number of rows in the input arrays\n",
    "    num_cases = means.shape[1]\n",
    "\n",
    "    # Initialize arrays to store the grand mean and standard error for each case\n",
    "    grand_means = np.zeros(num_cases)\n",
    "    grand_ses = np.zeros(num_cases)\n",
    "\n",
    "    for i in range(num_cases):\n",
    "        # Calculate the grand mean for this case\n",
    "        grand_means[i] = np.mean(means[:, i])\n",
    "        \n",
    "        # Calculate the weighted sum of squared standard errors for this case\n",
    "        weighted_ses_squared = np.sum((sample_sizes[:, i] - 1) * ses[:, i]**2)\n",
    "        \n",
    "        # Calculate the total degrees of freedom for this case\n",
    "        total_degrees_of_freedom = np.sum(sample_sizes[:, i] - 1)\n",
    "        \n",
    "        # Calculate the weighted variance for this case\n",
    "        weighted_variance = weighted_ses_squared / total_degrees_of_freedom\n",
    "        \n",
    "        # Calculate the standard error of the grand mean for this case\n",
    "        grand_ses[i] = np.sqrt(weighted_variance / means.shape[1])\n",
    "    \n",
    "    return grand_means, grand_ses\n",
    "\n",
    "\n",
    "# Set up the figure and axes\n",
    "case_names = ['Fixation', 'Endo', 'Exo']\n",
    "# ylims = [[-3e-8, 3e-8], [-3e-8, 3e-8], [-3e-8, 3e-8], [-1e-8, 1e-8]]\n",
    "# subtract_threshold = [0.25e-8, 0.25e-8, 0.25e-8, 0.25e-8]\n",
    "channels = [24, 25, 26, 28]\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=len(band_names), figsize=(12, 5))\n",
    "\n",
    "# for band, band_name in enumerate(band_names):\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 5))\n",
    "# ax = axes[band]\n",
    "# sham power increase\n",
    "sham = dfa_subtracts[0,channels,:]\n",
    "sham_ses = se_subtracts[0,channels,:]\n",
    "sham_mean_grand, sham_ses_grand  = calculate_grand_mean_and_se(sham, sham_ses, num_subtracts[0,channels,:])\n",
    "ax.errorbar(case_names, sham_mean_grand, yerr=sham_ses_grand, color='blue', label='Sham increase', marker='o', linestyle='-')\n",
    "\n",
    "real = dfa_subtracts[1,channels,:]\n",
    "real_ses = se_subtracts[1,channels,:]\n",
    "real_mean_grand, real_ses_grand  = calculate_grand_mean_and_se(real, real_ses, num_subtracts[1,channels,:])\n",
    "ax.errorbar(case_names, real_mean_grand, yerr=real_ses_grand, color='red', label='Real increase', marker='o', linestyle='-')\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--')\n",
    "ax.set_ylim([-0.04, 0.09])\n",
    "ax.set_xlabel('Trial type')\n",
    "ax.set_ylabel('Change of $\\u03B1$')\n",
    "# ax.set_title(band_name)\n",
    "\n",
    "    # if band == 0:\n",
    "    #     ax.set_ylabel('Band power increase')\n",
    "    # else:\n",
    "    #     ax.set_ylabel('')  # Clear the y-axis label\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.3)\n",
    "# fig.suptitle(case_title + ', by %', fontsize=20, y=1.1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
