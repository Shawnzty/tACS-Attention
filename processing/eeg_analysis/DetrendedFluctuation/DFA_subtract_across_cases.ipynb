{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# the following import is required for matplotlib < 3.2:\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, ttest_rel\n",
    "from scipy.signal import butter, filtfilt\n",
    "import mne\n",
    "import eeg_analysis.funcs4eeg as fe\n",
    "import re\n",
    "import imp\n",
    "import ast\n",
    "import behavior.func4behav as fb\n",
    "imp.reload(fe)\n",
    "imp.reload(fb)\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import resample\n",
    "from scipy.ndimage import zoom\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def align_slow(eeg, case, fs):\n",
    "    if 'endo' in case:\n",
    "        jump_from, jump_to = int((1.5+1+0.5)*fs), int((1.5+1+1)*fs)\n",
    "    elif 'exo' in case:\n",
    "        jump_from, jump_to = int((1.5+0.033*4+0.5)*fs), int((1.5+0.033*4+1)*fs)\n",
    "    \n",
    "    for channel in range(len(eeg)):\n",
    "        eeg[channel] = np.concatenate((eeg[channel][:,:jump_from], eeg[channel][:,jump_to:]), axis=1)\n",
    "        \n",
    "    return eeg\n",
    "\n",
    "case_title = 'endo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def dfa_alpha(data, min_win=25, max_win=200):\n",
    "    dfa_data = fu.toAggregated(data)\n",
    "    pydfa = fathon.DFA(dfa_data)\n",
    "    wins = fu.linRangeByStep(min_win, max_win)\n",
    "    n,F = pydfa.computeFlucVec(wins, revSeg=True, polOrd=3)\n",
    "    H, H_intercept = pydfa.fitFlucVec()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'exo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra\n",
    "\n",
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'all'\n",
    "case = 'all'\n",
    "\n",
    "fs = 1200\n",
    "\n",
    "watch = '1 fixation'\n",
    "tmin = 0 # include fix or not?\n",
    "tmax = 1.5\n",
    "\n",
    "highpass = None\n",
    "lowpass = None\n",
    "\n",
    "sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "\n",
    "\n",
    "stage = [0, 1.5]\n",
    "sessions = [sb, sa, rb, ra]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        tmp = np.empty(())\n",
    "        data = sessions[i][channel]\n",
    "        t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "        for trial_n in range(data.shape[0]):\n",
    "            one_trial = data[trial_n, t_start:t_end]\n",
    "            alpha = dfa_alpha(one_trial)\n",
    "            tmp = np.append(tmp, alpha)\n",
    "        # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "        mask = (tmp>0) & (tmp<2)\n",
    "        filtered_tmp = tmp[mask]\n",
    "        dfa_table_num[i, channel] = filtered_tmp.shape[0]\n",
    "        dfa_table_se[i, channel] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_fixation', dfa_table_se)\n",
    "np.save('dfa_num_fixation', dfa_table_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('dfa_table_'+case_title, dfa_table)\n",
    "# dfa_table = np.load('dfa_table_'+case_title+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# band = 0\n",
    "# fast, slow = bp_table[0,0,:,band], bp_table[0,1,:,band]\n",
    "\n",
    "# plt.scatter(range(len(fast)), fast, color='blue', label='fast')\n",
    "# plt.scatter(range(len(slow)), slow, color='red', label='slow')\n",
    "# plt.title(band)\n",
    "# plt.legend()\n",
    "# plt.ylim([0, 7e-8])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1402255256283456 1.4041407412572193\n"
     ]
    }
   ],
   "source": [
    "endo_means, exo_means, fix_means = np.load('dfa_data/dfa_mean_endo.npy'), np.load('dfa_data/dfa_mean_exo.npy'), np.load('dfa_data/dfa_mean_fixation.npy')\n",
    "exo_means = exo_means[:, :, 0]\n",
    "endo_nums, exo_nums, fix_nums = np.load('dfa_data/dfa_num_endo.npy'), np.load('dfa_data/dfa_num_exo.npy'), np.load('dfa_data/dfa_num_fixation.npy')\n",
    "exo_nums = exo_nums[:, :, 0]\n",
    "endo_se, exo_se, fix_se = np.load('dfa_data/dfa_se_endo.npy'), np.load('dfa_data/dfa_se_exo.npy'), np.load('dfa_data/dfa_se_fixation.npy')\n",
    "exo_se = exo_se[:, :, 0]\n",
    "\n",
    "print(np.min(fix_means), np.max(fix_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFA subtracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wait for cue for endo\n",
    "endo_dfa_subtracts, exo_dfa_subtracts, fix_dfa_subtracts = np.zeros((2, 32)),  np.zeros((2, 32)),  np.zeros((2, 32))\n",
    "endo_dfa_subtracts[0,:], endo_dfa_subtracts[1,:] = endo_means[1,:,1] - endo_means[0,:,1], endo_means[3,:,1] - endo_means[2,:,1]\n",
    "exo_dfa_subtracts[0,:], exo_dfa_subtracts[1,:] = exo_means[1,:] - exo_means[0,:], exo_means[3,:] - exo_means[2,:]\n",
    "fix_dfa_subtracts[0,:], fix_dfa_subtracts[1,:] = fix_means[1,:] - fix_means[0,:], fix_means[3,:] - fix_means[2,:]\n",
    "\n",
    "endo_se_subtracts, exo_se_subtracts, fix_se_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_se_subtracts[0,:], endo_se_subtracts[1,:] = np.sqrt(endo_se[1,:,1]**2 + endo_se[0,:,1]**2), np.sqrt(endo_se[3,:,1]**2 + endo_se[2,:,1]**2)\n",
    "exo_se_subtracts[0,:], exo_se_subtracts[1,:] = np.sqrt(exo_se[1,:]**2 + exo_se[0,:]**2), np.sqrt(exo_se[3,:]**2 + exo_se[2,:]**2)\n",
    "fix_se_subtracts[0,:], fix_se_subtracts[1,:] = np.sqrt(fix_se[1,:]**2 + fix_se[0,:]**2), np.sqrt(fix_se[3,:]**2 + fix_se[2,:]**2)\n",
    "\n",
    "endo_num_subtracts, exo_num_subtracts, fix_num_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_num_subtracts[0,:], endo_num_subtracts[1,:] = endo_nums[1,:,1] + endo_nums[0,:,1], endo_nums[3,:,1] + endo_nums[2,:,1]\n",
    "exo_num_subtracts[0,:], exo_num_subtracts[1,:] = exo_nums[1,:] + exo_nums[0,:], exo_nums[3,:] + exo_nums[2,:]\n",
    "fix_num_subtracts[0,:], fix_num_subtracts[1,:] = fix_nums[1,:] + fix_nums[0,:], fix_nums[3,:] + fix_nums[2,:]\n",
    "\n",
    "dfa_subtracts, se_subtracts, num_subtracts = np.zeros((2, 32, 3)), np.zeros((2, 32, 3)), np.zeros((2, 32, 3))\n",
    "dfa_subtracts[:,:,0], dfa_subtracts[:,:,1], dfa_subtracts[:,:,2] = fix_dfa_subtracts, endo_dfa_subtracts, exo_dfa_subtracts\n",
    "se_subtracts[:,:,0], se_subtracts[:,:,1], se_subtracts[:,:,2] = fix_se_subtracts, endo_se_subtracts, exo_se_subtracts\n",
    "num_subtracts[:,:,0], num_subtracts[:,:,1], num_subtracts[:,:,2] = fix_num_subtracts, endo_num_subtracts, exo_num_subtracts\n",
    "\n",
    "# common increase / decrease\n",
    "dfa_subtracts_positive = np.where(dfa_subtracts>0, 1, 0)\n",
    "dfa_subtracts_negative = np.where(dfa_subtracts<0, 1, 0)\n",
    "sham_positive = dfa_subtracts_positive[0,:,0] * dfa_subtracts_positive[0,:,1] * dfa_subtracts_positive[0,:,2]\n",
    "sham_negative = dfa_subtracts_negative[0,:,0] * dfa_subtracts_negative[0,:,1] * dfa_subtracts_negative[0,:,2]\n",
    "real_positive = dfa_subtracts_positive[1,:,0] * dfa_subtracts_positive[1,:,1] * dfa_subtracts_positive[1,:,2]\n",
    "real_negative = dfa_subtracts_negative[1,:,0] * dfa_subtracts_negative[1,:,1] * dfa_subtracts_negative[1,:,2]\n",
    "sham_increase_channels = np.where(sham_positive==1)[0]\n",
    "sham_decrease_channels = np.where(sham_negative==1)[0]\n",
    "real_increase_channels = np.where(real_positive==1)[0]\n",
    "real_decrease_channels = np.where(real_negative==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_grand_mean_and_se(means, ses, sample_sizes):\n",
    "     # Number of cases is the number of rows in the input arrays\n",
    "    num_cases = means.shape[1]\n",
    "\n",
    "    # Initialize arrays to store the grand mean and standard error for each case\n",
    "    grand_means = np.zeros(num_cases)\n",
    "    grand_ses = np.zeros(num_cases)\n",
    "\n",
    "    for i in range(num_cases):\n",
    "        # Calculate the grand mean for this case\n",
    "        grand_means[i] = np.mean(means[:, i])\n",
    "        \n",
    "        # Calculate the weighted sum of squared standard errors for this case\n",
    "        weighted_ses_squared = np.sum((sample_sizes[:, i] - 1) * ses[:, i]**2)\n",
    "        \n",
    "        # Calculate the total degrees of freedom for this case\n",
    "        total_degrees_of_freedom = np.sum(sample_sizes[:, i] - 1)\n",
    "        \n",
    "        # Calculate the weighted variance for this case\n",
    "        weighted_variance = weighted_ses_squared / total_degrees_of_freedom\n",
    "        \n",
    "        # Calculate the standard error of the grand mean for this case\n",
    "        grand_ses[i] = np.sqrt(weighted_variance / means.shape[1])\n",
    "    \n",
    "    return grand_means, grand_ses\n",
    "\n",
    "\n",
    "# Set up the figure and axes\n",
    "case_names = ['Fixation', 'Endo', 'Exo']\n",
    "# ylims = [[-3e-8, 3e-8], [-3e-8, 3e-8], [-3e-8, 3e-8], [-1e-8, 1e-8]]\n",
    "# subtract_threshold = [0.25e-8, 0.25e-8, 0.25e-8, 0.25e-8]\n",
    "channels = [24, 25, 26, 28]\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=len(band_names), figsize=(12, 5))\n",
    "\n",
    "# for band, band_name in enumerate(band_names):\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 5))\n",
    "# ax = axes[band]\n",
    "# sham power increase\n",
    "sham = dfa_subtracts[0,channels,:]\n",
    "sham_ses = se_subtracts[0,channels,:]\n",
    "sham_mean_grand, sham_ses_grand  = calculate_grand_mean_and_se(sham, sham_ses, num_subtracts[0,channels,:])\n",
    "ax.errorbar(case_names, sham_mean_grand, yerr=sham_ses_grand, color='blue', label='Sham increase', marker='o', linestyle='-')\n",
    "\n",
    "real = dfa_subtracts[1,channels,:]\n",
    "real_ses = se_subtracts[1,channels,:]\n",
    "real_mean_grand, real_ses_grand  = calculate_grand_mean_and_se(real, real_ses, num_subtracts[1,channels,:])\n",
    "ax.errorbar(case_names, real_mean_grand, yerr=real_ses_grand, color='red', label='Real increase', marker='o', linestyle='-')\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--')\n",
    "ax.set_ylim([-0.1, 0.1])\n",
    "ax.set_xlabel('Trial type')\n",
    "ax.set_ylabel('Change of $\\u03B1$')\n",
    "# ax.set_title(band_name)\n",
    "\n",
    "    # if band == 0:\n",
    "    #     ax.set_ylabel('Band power increase')\n",
    "    # else:\n",
    "    #     ax.set_ylabel('')  # Clear the y-axis label\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.3)\n",
    "# fig.suptitle(case_title + ', by %', fontsize=20, y=1.1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
