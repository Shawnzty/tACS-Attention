{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# the following import is required for matplotlib < 3.2:\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, ttest_rel\n",
    "from scipy.signal import butter, filtfilt\n",
    "import mne\n",
    "import eeg_analysis.funcs4eeg as fe\n",
    "import re\n",
    "import imp\n",
    "import ast\n",
    "import behavior.func4behav as fb\n",
    "imp.reload(fe)\n",
    "imp.reload(fb)\n",
    "import matplotlib\n",
    "from scipy import signal\n",
    "from scipy.signal import resample\n",
    "from scipy.ndimage import zoom\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def align_slow(eeg, case, fs):\n",
    "    if 'endo' in case:\n",
    "        jump_from, jump_to = int((1.5+1+0.5)*fs), int((1.5+1+1)*fs)\n",
    "    elif 'exo' in case:\n",
    "        jump_from, jump_to = int((1.5+0.033*4+0.5)*fs), int((1.5+0.033*4+1)*fs)\n",
    "    \n",
    "    for channel in range(len(eeg)):\n",
    "        eeg[channel] = np.concatenate((eeg[channel][:,:jump_from], eeg[channel][:,jump_to:]), axis=1)\n",
    "        \n",
    "    return eeg\n",
    "\n",
    "case_title = 'endo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def dfa_alpha(data, min_win=25, max_win=200):\n",
    "    dfa_data = fu.toAggregated(data)\n",
    "    pydfa = fathon.DFA(dfa_data)\n",
    "    wins = fu.linRangeByStep(min_win, max_win)\n",
    "    n,F = pydfa.computeFlucVec(wins, revSeg=True, polOrd=3)\n",
    "    H, H_intercept = pydfa.fitFlucVec()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'exo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra\n",
    "\n",
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'all'\n",
    "case = 'all'\n",
    "\n",
    "fs = 1200\n",
    "\n",
    "watch = '1 fixation'\n",
    "tmin = 0 # include fix or not?\n",
    "tmax = 1.5\n",
    "\n",
    "highpass = None\n",
    "lowpass = None\n",
    "\n",
    "sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "\n",
    "stage = [0, 1.5]\n",
    "sessions = [sb, sa, rb, ra]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        tmp = np.empty(())\n",
    "        data = sessions[i][channel]\n",
    "        t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "        for trial_n in range(data.shape[0]):\n",
    "            one_trial = data[trial_n, t_start:t_end]\n",
    "            alpha = dfa_alpha(one_trial)\n",
    "            tmp = np.append(tmp, alpha)\n",
    "        # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "        mask = (tmp>0) & (tmp<2)\n",
    "        filtered_tmp = tmp[mask]\n",
    "        dfa_table_num[i, channel] = filtered_tmp.shape[0]\n",
    "        dfa_table_se[i, channel] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_fixation', dfa_table_se)\n",
    "np.save('dfa_num_fixation', dfa_table_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('dfa_table_'+case_title, dfa_table)\n",
    "# dfa_table = np.load('dfa_table_'+case_title+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# band = 0\n",
    "# fast, slow = bp_table[0,0,:,band], bp_table[0,1,:,band]\n",
    "\n",
    "# plt.scatter(range(len(fast)), fast, color='blue', label='fast')\n",
    "# plt.scatter(range(len(slow)), slow, color='red', label='slow')\n",
    "# plt.title(band)\n",
    "# plt.legend()\n",
    "# plt.ylim([0, 7e-8])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1402255256283456 1.4041407412572193\n"
     ]
    }
   ],
   "source": [
    "endo_means, exo_means, fix_means = np.load('dfa_data/dfa_mean_endo.npy'), np.load('dfa_data/dfa_mean_exo.npy'), np.load('dfa_data/dfa_mean_fixation.npy')\n",
    "exo_means = exo_means[:, :, 0]\n",
    "endo_nums, exo_nums, fix_nums = np.load('dfa_data/dfa_num_endo.npy'), np.load('dfa_data/dfa_num_exo.npy'), np.load('dfa_data/dfa_num_fixation.npy')\n",
    "exo_nums = exo_nums[:, :, 0]\n",
    "endo_se, exo_se, fix_se = np.load('dfa_data/dfa_se_endo.npy'), np.load('dfa_data/dfa_se_exo.npy'), np.load('dfa_data/dfa_se_fixation.npy')\n",
    "exo_se = exo_se[:, :, 0]\n",
    "\n",
    "print(np.min(fix_means), np.max(fix_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFA subtracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wait for cue for endo\n",
    "endo_dfa_subtracts, exo_dfa_subtracts, fix_dfa_subtracts = np.zeros((2, 32)),  np.zeros((2, 32)),  np.zeros((2, 32))\n",
    "endo_dfa_subtracts[0,:], endo_dfa_subtracts[1,:] = endo_means[1,:,1] - endo_means[0,:,1], endo_means[3,:,1] - endo_means[2,:,1]\n",
    "exo_dfa_subtracts[0,:], exo_dfa_subtracts[1,:] = exo_means[1,:] - exo_means[0,:], exo_means[3,:] - exo_means[2,:]\n",
    "fix_dfa_subtracts[0,:], fix_dfa_subtracts[1,:] = fix_means[1,:] - fix_means[0,:], fix_means[3,:] - fix_means[2,:]\n",
    "\n",
    "endo_se_subtracts, exo_se_subtracts, fix_se_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_se_subtracts[0,:], endo_se_subtracts[1,:] = np.sqrt(endo_se[1,:,1]**2 + endo_se[0,:,1]**2), np.sqrt(endo_se[3,:,1]**2 + endo_se[2,:,1]**2)\n",
    "exo_se_subtracts[0,:], exo_se_subtracts[1,:] = np.sqrt(exo_se[1,:]**2 + exo_se[0,:]**2), np.sqrt(exo_se[3,:]**2 + exo_se[2,:]**2)\n",
    "fix_se_subtracts[0,:], fix_se_subtracts[1,:] = np.sqrt(fix_se[1,:]**2 + fix_se[0,:]**2), np.sqrt(fix_se[3,:]**2 + fix_se[2,:]**2)\n",
    "\n",
    "endo_num_subtracts, exo_num_subtracts, fix_num_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_num_subtracts[0,:], endo_num_subtracts[1,:] = endo_nums[1,:,1] + endo_nums[0,:,1], endo_nums[3,:,1] + endo_nums[2,:,1]\n",
    "exo_num_subtracts[0,:], exo_num_subtracts[1,:] = exo_nums[1,:] + exo_nums[0,:], exo_nums[3,:] + exo_nums[2,:]\n",
    "fix_num_subtracts[0,:], fix_num_subtracts[1,:] = fix_nums[1,:] + fix_nums[0,:], fix_nums[3,:] + fix_nums[2,:]\n",
    "\n",
    "dfa_subtracts, se_subtracts, num_subtracts = np.zeros((2, 32, 3)), np.zeros((2, 32, 3)), np.zeros((2, 32, 3))\n",
    "dfa_subtracts[:,:,0], dfa_subtracts[:,:,1], dfa_subtracts[:,:,2] = fix_dfa_subtracts, endo_dfa_subtracts, exo_dfa_subtracts\n",
    "se_subtracts[:,:,0], se_subtracts[:,:,1], se_subtracts[:,:,2] = fix_se_subtracts, endo_se_subtracts, exo_se_subtracts\n",
    "num_subtracts[:,:,0], num_subtracts[:,:,1], num_subtracts[:,:,2] = fix_num_subtracts, endo_num_subtracts, exo_num_subtracts\n",
    "\n",
    "# common increase / decrease\n",
    "dfa_subtracts_positive = np.where(dfa_subtracts>0, 1, 0)\n",
    "dfa_subtracts_negative = np.where(dfa_subtracts<0, 1, 0)\n",
    "sham_positive = dfa_subtracts_positive[0,:,0] * dfa_subtracts_positive[0,:,1] * dfa_subtracts_positive[0,:,2]\n",
    "sham_negative = dfa_subtracts_negative[0,:,0] * dfa_subtracts_negative[0,:,1] * dfa_subtracts_negative[0,:,2]\n",
    "real_positive = dfa_subtracts_positive[1,:,0] * dfa_subtracts_positive[1,:,1] * dfa_subtracts_positive[1,:,2]\n",
    "real_negative = dfa_subtracts_negative[1,:,0] * dfa_subtracts_negative[1,:,1] * dfa_subtracts_negative[1,:,2]\n",
    "sham_increase_channels = np.where(sham_positive==1)[0]\n",
    "sham_decrease_channels = np.where(sham_negative==1)[0]\n",
    "real_increase_channels = np.where(real_positive==1)[0]\n",
    "real_decrease_channels = np.where(real_negative==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 148.819x275.591 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_grand_mean_and_se(means, ses, sample_sizes):\n",
    "     # Number of cases is the number of rows in the input arrays\n",
    "    num_cases = means.shape[1]\n",
    "\n",
    "    # Initialize arrays to store the grand mean and standard error for each case\n",
    "    grand_means = np.zeros(num_cases)\n",
    "    grand_ses = np.zeros(num_cases)\n",
    "\n",
    "    for i in range(num_cases):\n",
    "        # Calculate the grand mean for this case\n",
    "        grand_means[i] = np.mean(means[:, i])\n",
    "        \n",
    "        # Calculate the weighted sum of squared standard errors for this case\n",
    "        weighted_ses_squared = np.sum((sample_sizes[:, i] - 1) * ses[:, i]**2)\n",
    "        \n",
    "        # Calculate the total degrees of freedom for this case\n",
    "        total_degrees_of_freedom = np.sum(sample_sizes[:, i] - 1)\n",
    "        \n",
    "        # Calculate the weighted variance for this case\n",
    "        weighted_variance = weighted_ses_squared / total_degrees_of_freedom\n",
    "        \n",
    "        # Calculate the standard error of the grand mean for this case\n",
    "        grand_ses[i] = np.sqrt(weighted_variance / means.shape[1])\n",
    "    \n",
    "    return grand_means, grand_ses\n",
    "\n",
    "\n",
    "# Set up the figure and axes\n",
    "case_names = ['Fix', 'Endo', 'Exo']\n",
    "# ylims = [[-3e-8, 3e-8], [-3e-8, 3e-8], [-3e-8, 3e-8], [-1e-8, 1e-8]]\n",
    "# subtract_threshold = [0.25e-8, 0.25e-8, 0.25e-8, 0.25e-8]\n",
    "channels = [24, 25, 26, 28]\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=len(band_names), figsize=(12, 5))\n",
    "\n",
    "# for band, band_name in enumerate(band_names):\n",
    "cm = 1/2.54\n",
    "fig, ax = plt.subplots(figsize=(3.78*cm, 7*cm))\n",
    "# ax = axes[band]\n",
    "# sham power increase\n",
    "line_width = 1\n",
    "marker_size = 2\n",
    "\n",
    "sham = dfa_subtracts[0,channels,:]\n",
    "sham_ses = se_subtracts[0,channels,:]\n",
    "sham_mean_grand, sham_ses_grand  = calculate_grand_mean_and_se(sham, sham_ses, num_subtracts[0,channels,:])\n",
    "ax.errorbar(case_names, sham_mean_grand, yerr=sham_ses_grand, color='blue', label='Sham increase', marker='o', linestyle='-', linewidth = line_width, markersize=marker_size)\n",
    "\n",
    "real = dfa_subtracts[1,channels,:]\n",
    "real_ses = se_subtracts[1,channels,:]\n",
    "real_mean_grand, real_ses_grand  = calculate_grand_mean_and_se(real, real_ses, num_subtracts[1,channels,:])\n",
    "ax.errorbar(case_names, real_mean_grand, yerr=real_ses_grand, color='red', label='Real increase', marker='o', linestyle='-', linewidth = line_width, markersize=marker_size)\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=line_width)\n",
    "ax.set_ylim([-0.04, 0.09])\n",
    "# ax.set_xlabel('Trial type')\n",
    "ax.set_ylabel('$\\u0394$$\\u03B1$', labelpad=-2)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 7})\n",
    "fig.subplots_adjust(left=0.35, bottom=0.08, right=0.96, top=0.97)\n",
    "# plt.subplots_adjust(wspace=0.3)\n",
    "# plt.tight_layout()\n",
    "save_path = os.path.join('..', '..', '..', '..', 'paper', 'Figure 5', 'alpha_change.eps')\n",
    "plt.savefig(save_path, format='eps')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
