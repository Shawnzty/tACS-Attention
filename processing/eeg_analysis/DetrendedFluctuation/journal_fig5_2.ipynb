{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# the following import is required for matplotlib < 3.2:\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, ttest_rel\n",
    "from scipy.signal import butter, filtfilt\n",
    "import mne\n",
    "import eeg_analysis.funcs4eeg as fe\n",
    "import re\n",
    "import imp\n",
    "import ast\n",
    "import behavior.func4behav as fb\n",
    "imp.reload(fe)\n",
    "imp.reload(fb)\n",
    "import matplotlib\n",
    "from scipy import signal\n",
    "from scipy.signal import resample\n",
    "from scipy.ndimage import zoom\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\behavior\\func4behav.py:158: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\behavior\\func4behav.py:158: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tACS-Attention\\processing\\eeg_analysis\\funcs4eeg.py:181: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  evoked = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "def align_slow(eeg, case, fs):\n",
    "    if 'endo' in case:\n",
    "        jump_from, jump_to = int((1.5+1+0.5)*fs), int((1.5+1+1)*fs)\n",
    "    elif 'exo' in case:\n",
    "        jump_from, jump_to = int((1.5+0.033*4+0.5)*fs), int((1.5+0.033*4+1)*fs)\n",
    "    \n",
    "    for channel in range(len(eeg)):\n",
    "        eeg[channel] = np.concatenate((eeg[channel][:,:jump_from], eeg[channel][:,jump_to:]), axis=1)\n",
    "        \n",
    "    return eeg\n",
    "\n",
    "case_title = 'endo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def dfa_alpha(data, min_win=25, max_win=200):\n",
    "    dfa_data = fu.toAggregated(data)\n",
    "    pydfa = fathon.DFA(dfa_data)\n",
    "    wins = fu.linRangeByStep(min_win, max_win)\n",
    "    n,F = pydfa.computeFlucVec(wins, revSeg=True, polOrd=3)\n",
    "    H, H_intercept = pydfa.fitFlucVec()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.5, 2.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[2.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1.5, 3.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trial_n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     17\u001b[0m         one_trial \u001b[38;5;241m=\u001b[39m data[trial_n, t_start:t_end]\n\u001b[1;32m---> 18\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m \u001b[43mdfa_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m         tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(tmp, alpha)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mdfa_alpha\u001b[1;34m(data, min_win, max_win)\u001b[0m\n\u001b[0;32m     11\u001b[0m pydfa \u001b[38;5;241m=\u001b[39m fathon\u001b[38;5;241m.\u001b[39mDFA(dfa_data)\n\u001b[0;32m     12\u001b[0m wins \u001b[38;5;241m=\u001b[39m fu\u001b[38;5;241m.\u001b[39mlinRangeByStep(min_win, max_win)\n\u001b[1;32m---> 13\u001b[0m n,F \u001b[38;5;241m=\u001b[39m \u001b[43mpydfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeFlucVec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevSeg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolOrd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m H, H_intercept \u001b[38;5;241m=\u001b[39m pydfa\u001b[38;5;241m.\u001b[39mfitFlucVec()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m H\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n",
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "[1.6320000000000001, 2.132]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[1, 1.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'exo'\n",
    "case_list = [case_title+' fast', case_title+' slow']\n",
    "if 'endo' in case_title:\n",
    "    tmax_list = [1.5+1+0.5+0.05+0.2, 1.5+1+1+0.05+0.2]\n",
    "else:\n",
    "    tmax_list = [1.5+0.033*4+0.5+0.05+0.2, 1.5+0.033*4+1+0.05+0.2]\n",
    "\n",
    "fs = 1200\n",
    "for i, case in enumerate(case_list):\n",
    "    tmax = tmax_list[i]\n",
    "    watch = '1 fixation'\n",
    "    tmin = 0 # include fix or not?\n",
    "\n",
    "    highpass = None\n",
    "    lowpass = None\n",
    "\n",
    "    sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "    \n",
    "    if 'slow' in case:\n",
    "        # sham_before_slow = align_slow(sb, case, fs)\n",
    "        # sham_after_slow = align_slow(sa, case, fs)\n",
    "        # real_before_slow = align_slow(rb, case, fs)\n",
    "        # real_after_slow = align_slow(ra, case, fs)\n",
    "\n",
    "        sham_before_slow = sb\n",
    "        sham_after_slow = sa\n",
    "        real_before_slow = rb\n",
    "        real_after_slow = ra\n",
    "\n",
    "    else:\n",
    "        sham_before_fast = sb\n",
    "        sham_after_fast = sa\n",
    "        real_before_fast = rb\n",
    "        real_after_fast = ra\n",
    "\n",
    "# exclude fixation\n",
    "endo_fast_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+0.5], [1.5, 1.5+1+0.5]]\n",
    "endo_slow_stages = [[1.5, 1.5+1], [1.5+1, 1.5+1+1], [1.5, 1.5+1+1]]\n",
    "exo_fast_stages = [[1.5+0.033*4, 1.5+0.033*4+0.5], [1, 1.5], [1, 1.5]] # the second and third ones are fake, only for occupy the place\n",
    "exo_slow_stages = [[1.5+0.033*4, 1.5+0.033*4+1], [1, 1.5], [1, 1.5]]\n",
    "\n",
    "if 'endo' in case_title:\n",
    "    stages = [endo_fast_stages, endo_slow_stages]\n",
    "else:\n",
    "    stages = [exo_fast_stages, exo_slow_stages]\n",
    "\n",
    "slow_sessions = [sham_before_slow, sham_after_slow, real_before_slow, real_after_slow]\n",
    "fast_sessions = [sham_before_fast, sham_after_fast, real_before_fast, real_after_fast]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32, 3)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for k in range(3): # stages\n",
    "        print(stages[0][k])\n",
    "        for i in range(4):\n",
    "            print(i)\n",
    "            tmp = np.empty(())\n",
    "            fast_session = fast_sessions[i][channel]\n",
    "            slow_session = slow_sessions[i][channel]\n",
    "            for j, data in enumerate([fast_session, slow_session]):\n",
    "                stage = stages[j][k]\n",
    "                t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "                for trial_n in range(data.shape[0]):\n",
    "                    one_trial = data[trial_n, t_start:t_end]\n",
    "                    alpha = dfa_alpha(one_trial)\n",
    "                    tmp = np.append(tmp, alpha)\n",
    "            # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "            mask = (tmp>0) & (tmp<2)\n",
    "            filtered_tmp = tmp[mask]\n",
    "            dfa_table_num[i, channel, k] = filtered_tmp.shape[0]\n",
    "            dfa_table_se[i, channel, k] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_'+case_title, dfa_table_se)\n",
    "np.save('dfa_num_'+case_title, dfa_table_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tianyi Zheng\\OneDrive - neuron.t.u-tokyo.ac.jp\\Documents\\zheng\\mywork\\attention_tES\\tes-attention\\processing\\behavior\\func4behav.py:155: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  behavior_compare = pd.concat([behavior_compare, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "26\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "27\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "28\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "case_title = 'all'\n",
    "case = 'all'\n",
    "\n",
    "fs = 1200\n",
    "\n",
    "watch = '1 fixation'\n",
    "tmin = 0 # include fix or not?\n",
    "tmax = 1.5\n",
    "\n",
    "highpass = None\n",
    "lowpass = None\n",
    "\n",
    "sb, sa, rb, ra = fe.pipeline_session_channel(case, watch, tmin, tmax, hipass=highpass, lopass=lowpass, baseline=(0,0), detrend=0)\n",
    "\n",
    "stage = [0, 1.5]\n",
    "sessions = [sb, sa, rb, ra]\n",
    "\n",
    "dfa_table_se = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "dfa_table_num = np.zeros((4, 32)) # 4 sessions, 32 channels, 2 stages\n",
    "\n",
    "for channel in range(32):\n",
    "    print(channel)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        tmp = np.empty(())\n",
    "        data = sessions[i][channel]\n",
    "        t_start, t_end = int(stage[0]*fs), int(stage[1]*fs)\n",
    "        for trial_n in range(data.shape[0]):\n",
    "            one_trial = data[trial_n, t_start:t_end]\n",
    "            alpha = dfa_alpha(one_trial)\n",
    "            tmp = np.append(tmp, alpha)\n",
    "        # tmp = fe.rm_outlier(tmp, lower_k=3, upper_k=100, verbose=False)\n",
    "        mask = (tmp>0) & (tmp<2)\n",
    "        filtered_tmp = tmp[mask]\n",
    "        dfa_table_num[i, channel] = filtered_tmp.shape[0]\n",
    "        dfa_table_se[i, channel] = filtered_tmp.std()/np.sqrt(filtered_tmp.shape[0])\n",
    "\n",
    "np.save('dfa_se_fixation', dfa_table_se)\n",
    "np.save('dfa_num_fixation', dfa_table_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('dfa_table_'+case_title, dfa_table)\n",
    "# dfa_table = np.load('dfa_table_'+case_title+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# band = 0\n",
    "# fast, slow = bp_table[0,0,:,band], bp_table[0,1,:,band]\n",
    "\n",
    "# plt.scatter(range(len(fast)), fast, color='blue', label='fast')\n",
    "# plt.scatter(range(len(slow)), slow, color='red', label='slow')\n",
    "# plt.title(band)\n",
    "# plt.legend()\n",
    "# plt.ylim([0, 7e-8])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1402255256283456 1.4041407412572193\n"
     ]
    }
   ],
   "source": [
    "endo_means, exo_means, fix_means = np.load('dfa_data/dfa_mean_endo.npy'), np.load('dfa_data/dfa_mean_exo.npy'), np.load('dfa_data/dfa_mean_fixation.npy')\n",
    "exo_means = exo_means[:, :, 0]\n",
    "endo_nums, exo_nums, fix_nums = np.load('dfa_data/dfa_num_endo.npy'), np.load('dfa_data/dfa_num_exo.npy'), np.load('dfa_data/dfa_num_fixation.npy')\n",
    "exo_nums = exo_nums[:, :, 0]\n",
    "endo_se, exo_se, fix_se = np.load('dfa_data/dfa_se_endo.npy'), np.load('dfa_data/dfa_se_exo.npy'), np.load('dfa_data/dfa_se_fixation.npy')\n",
    "exo_se = exo_se[:, :, 0]\n",
    "\n",
    "print(np.min(fix_means), np.max(fix_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFA subtracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wait for cue for endo\n",
    "endo_dfa_subtracts, exo_dfa_subtracts, fix_dfa_subtracts = np.zeros((2, 32)),  np.zeros((2, 32)),  np.zeros((2, 32))\n",
    "endo_dfa_subtracts[0,:], endo_dfa_subtracts[1,:] = endo_means[1,:,1] - endo_means[0,:,1], endo_means[3,:,1] - endo_means[2,:,1]\n",
    "exo_dfa_subtracts[0,:], exo_dfa_subtracts[1,:] = exo_means[1,:] - exo_means[0,:], exo_means[3,:] - exo_means[2,:]\n",
    "fix_dfa_subtracts[0,:], fix_dfa_subtracts[1,:] = fix_means[1,:] - fix_means[0,:], fix_means[3,:] - fix_means[2,:]\n",
    "\n",
    "endo_se_subtracts, exo_se_subtracts, fix_se_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_se_subtracts[0,:], endo_se_subtracts[1,:] = np.sqrt(endo_se[1,:,1]**2 + endo_se[0,:,1]**2), np.sqrt(endo_se[3,:,1]**2 + endo_se[2,:,1]**2)\n",
    "exo_se_subtracts[0,:], exo_se_subtracts[1,:] = np.sqrt(exo_se[1,:]**2 + exo_se[0,:]**2), np.sqrt(exo_se[3,:]**2 + exo_se[2,:]**2)\n",
    "fix_se_subtracts[0,:], fix_se_subtracts[1,:] = np.sqrt(fix_se[1,:]**2 + fix_se[0,:]**2), np.sqrt(fix_se[3,:]**2 + fix_se[2,:]**2)\n",
    "\n",
    "endo_num_subtracts, exo_num_subtracts, fix_num_subtracts = np.zeros((2, 32)), np.zeros((2, 32)), np.zeros((2, 32))\n",
    "endo_num_subtracts[0,:], endo_num_subtracts[1,:] = endo_nums[1,:,1] + endo_nums[0,:,1], endo_nums[3,:,1] + endo_nums[2,:,1]\n",
    "exo_num_subtracts[0,:], exo_num_subtracts[1,:] = exo_nums[1,:] + exo_nums[0,:], exo_nums[3,:] + exo_nums[2,:]\n",
    "fix_num_subtracts[0,:], fix_num_subtracts[1,:] = fix_nums[1,:] + fix_nums[0,:], fix_nums[3,:] + fix_nums[2,:]\n",
    "\n",
    "dfa_subtracts, se_subtracts, num_subtracts = np.zeros((2, 32, 3)), np.zeros((2, 32, 3)), np.zeros((2, 32, 3))\n",
    "dfa_subtracts[:,:,0], dfa_subtracts[:,:,1], dfa_subtracts[:,:,2] = fix_dfa_subtracts, endo_dfa_subtracts, exo_dfa_subtracts\n",
    "se_subtracts[:,:,0], se_subtracts[:,:,1], se_subtracts[:,:,2] = fix_se_subtracts, endo_se_subtracts, exo_se_subtracts\n",
    "num_subtracts[:,:,0], num_subtracts[:,:,1], num_subtracts[:,:,2] = fix_num_subtracts, endo_num_subtracts, exo_num_subtracts\n",
    "\n",
    "# common increase / decrease\n",
    "dfa_subtracts_positive = np.where(dfa_subtracts>0, 1, 0)\n",
    "dfa_subtracts_negative = np.where(dfa_subtracts<0, 1, 0)\n",
    "sham_positive = dfa_subtracts_positive[0,:,0] * dfa_subtracts_positive[0,:,1] * dfa_subtracts_positive[0,:,2]\n",
    "sham_negative = dfa_subtracts_negative[0,:,0] * dfa_subtracts_negative[0,:,1] * dfa_subtracts_negative[0,:,2]\n",
    "real_positive = dfa_subtracts_positive[1,:,0] * dfa_subtracts_positive[1,:,1] * dfa_subtracts_positive[1,:,2]\n",
    "real_negative = dfa_subtracts_negative[1,:,0] * dfa_subtracts_negative[1,:,1] * dfa_subtracts_negative[1,:,2]\n",
    "sham_increase_channels = np.where(sham_positive==1)[0]\n",
    "sham_decrease_channels = np.where(sham_negative==1)[0]\n",
    "real_increase_channels = np.where(real_positive==1)[0]\n",
    "real_decrease_channels = np.where(real_negative==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 275.591x275.591 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_grand_mean_and_se(means, ses, sample_sizes):\n",
    "     # Number of cases is the number of rows in the input arrays\n",
    "    num_cases = means.shape[1]\n",
    "\n",
    "    # Initialize arrays to store the grand mean and standard error for each case\n",
    "    grand_means = np.zeros(num_cases)\n",
    "    grand_ses = np.zeros(num_cases)\n",
    "\n",
    "    for i in range(num_cases):\n",
    "        # Calculate the grand mean for this case\n",
    "        grand_means[i] = np.mean(means[:, i])\n",
    "        \n",
    "        # Calculate the weighted sum of squared standard errors for this case\n",
    "        weighted_ses_squared = np.sum((sample_sizes[:, i] - 1) * ses[:, i]**2)\n",
    "        \n",
    "        # Calculate the total degrees of freedom for this case\n",
    "        total_degrees_of_freedom = np.sum(sample_sizes[:, i] - 1)\n",
    "        \n",
    "        # Calculate the weighted variance for this case\n",
    "        weighted_variance = weighted_ses_squared / total_degrees_of_freedom\n",
    "        \n",
    "        # Calculate the standard error of the grand mean for this case\n",
    "        grand_ses[i] = np.sqrt(weighted_variance / means.shape[1])\n",
    "    \n",
    "    return grand_means, grand_ses\n",
    "\n",
    "\n",
    "# Set up the figure and axes\n",
    "case_names = ['Fix', 'Endo', 'Exo']\n",
    "# ylims = [[-3e-8, 3e-8], [-3e-8, 3e-8], [-3e-8, 3e-8], [-1e-8, 1e-8]]\n",
    "# subtract_threshold = [0.25e-8, 0.25e-8, 0.25e-8, 0.25e-8]\n",
    "channels = [24, 25, 26, 28]\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=len(band_names), figsize=(12, 5))\n",
    "\n",
    "# for band, band_name in enumerate(band_names):\n",
    "cm = 1/2.54\n",
    "# for journal paper\n",
    "fig, ax = plt.subplots(figsize=(3.78*cm, 7*cm))\n",
    "\n",
    "# FOR THESIS\n",
    "# fig, ax = plt.subplots(figsize=(7*cm, 7*cm))\n",
    "\n",
    "# ax = axes[band]\n",
    "# sham power increase\n",
    "line_width = 1\n",
    "marker_size = 2\n",
    "\n",
    "sham = dfa_subtracts[0,channels,:]\n",
    "sham_ses = se_subtracts[0,channels,:]\n",
    "sham_mean_grand, sham_ses_grand  = calculate_grand_mean_and_se(sham, sham_ses, num_subtracts[0,channels,:])\n",
    "ax.errorbar(case_names, sham_mean_grand, yerr=sham_ses_grand, color='blue', label='Sham increase', marker='o', linestyle='-', linewidth = line_width, markersize=marker_size)\n",
    "\n",
    "real = dfa_subtracts[1,channels,:]\n",
    "real_ses = se_subtracts[1,channels,:]\n",
    "real_mean_grand, real_ses_grand  = calculate_grand_mean_and_se(real, real_ses, num_subtracts[1,channels,:])\n",
    "ax.errorbar(case_names, real_mean_grand, yerr=real_ses_grand, color='red', label='Real increase', marker='o', linestyle='-', linewidth = line_width, markersize=marker_size)\n",
    "\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=line_width)\n",
    "ax.set_ylim([-0.04, 0.09])\n",
    "# ax.set_xlabel('Trial type')\n",
    "ax.set_ylabel('$\\u0394$$\\u03B1$', labelpad=-2)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 7})\n",
    "fig.subplots_adjust(left=0.35, bottom=0.08, right=0.96, top=0.97)\n",
    "# plt.subplots_adjust(wspace=0.3)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# for journal paper\n",
    "save_path = os.path.join('..', '..', '..', '..', 'paper', 'Figure 5', 'alpha_change.eps')\n",
    "\n",
    "# for thesis\n",
    "# save_path = os.path.join('..', '..', '..', '..', '..', '..', 'DThesis', 'chapter3', 'alpha_change.eps')\n",
    "\n",
    "\n",
    "plt.savefig(save_path, format='eps')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
